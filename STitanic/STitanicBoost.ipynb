{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "np.random.seed(42)\n",
    "import seaborn as sns\n",
    "import scipy\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv(\"./train.csv\")\n",
    "test_data = pd. read_csv(\"./test.csv\")\n",
    "\n",
    "sub_ids = test_data[\"PassengerId\"].to_frame()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_in_train = sum([True for idx,row in train_data.iterrows() if any(row.isnull())])\n",
    "missing_in_test = sum([True for idx,row in test_data.iterrows() if any(row.isnull())])\n",
    "\n",
    "f\"There are {missing_in_train} missing rows in train and {missing_in_test} missing rows in test\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_frame_ready(source_frame: pd.DataFrame) -> pd.DataFrame:\n",
    "    \n",
    "\n",
    "    #make new column group from the passengerId\n",
    "    source_frame[\"Group\"] = source_frame[\"PassengerId\"].apply(lambda x: x.split(\"_\")[0])\n",
    "\n",
    "    #make new column family from the name of the passenger\n",
    "    source_frame[\"Family\"] = source_frame[\"Name\"].apply(lambda x: str(x).split(\" \")[-1])\n",
    "\n",
    "\n",
    "    #impute missing family from group\n",
    "    #source_frame[\"Family\"] = source_frame.groupby(\"Group\")[\"Family\"].ffill().bfill()\n",
    "    source_frame[\"Family\"] = source_frame[\"Family\"].fillna(source_frame.groupby(\"Group\")[\"Family\"].agg(lambda x: pd.Series.mode(x, dropna=True)))\n",
    "\n",
    "    #TODO impute missing cabins from families\n",
    "    source_frame[\"Cabin\"] = source_frame[\"Cabin\"].fillna(source_frame.groupby(\"Group\")[\"Cabin\"].agg(lambda x: pd.Series.mode(x, dropna=True)))\n",
    "    source_frame[\"Cabin\"].ffill(inplace=True)\n",
    "\n",
    "    #split cabin infor into three parts\n",
    "    source_frame[[\"Deck\", \"Num\", \"shipSide\"]] = source_frame[\"Cabin\"].str.split(\"/\", expand=True)\n",
    "    source_frame[\"Num\"] = source_frame[\"Num\"].astype(np.float64)\n",
    "\n",
    "    #Put cabin number into bins\n",
    "    source_frame[\"NumGroup\"] = pd.cut(source_frame[\"Num\"], bins=12).cat.codes\n",
    "\n",
    "    \n",
    "    #create age bins\n",
    "    source_frame[\"AgeGroup\"] = pd.cut(source_frame[\"Age\"], bins=8).cat.codes\n",
    "\n",
    "    #set spending for cryosleepers\n",
    "    source_frame.loc[source_frame[\"CryoSleep\"] == True ,[\"RoomService\", \"FoodCourt\", \"ShoppingMall\", \"Spa\", \"VRDeck\"]] = 0.0\n",
    "\n",
    "    # set spending of all kids to zero\n",
    "    source_frame.loc[source_frame[\"Age\"] <= 12, [\"RoomService\", \"FoodCourt\", \"ShoppingMall\", \"Spa\", \"VRDeck\"]] = 0.0\n",
    "\n",
    "    #create totalSpending column\n",
    "    source_frame[\"totalSpent\"] = source_frame[[\"RoomService\", \"FoodCourt\", \"ShoppingMall\", \"Spa\", \"VRDeck\"]].sum(axis=1)\n",
    "\n",
    "    source_frame[\"SpendingGroup\"] = pd.cut(source_frame[\"totalSpent\"], bins = 10).cat.codes\n",
    "\n",
    "\n",
    "    #set age of all people not spending to average age for people 12 and under\n",
    "    source_frame[\"Age\"] = np.where((source_frame.CryoSleep == False) & (\n",
    "    source_frame.Age.isna()) & (source_frame.totalSpent == 0), 5, source_frame.Age)\n",
    "    \n",
    "    #impute VIP status by spending   \n",
    "    source_frame.loc[(source_frame.VIP.isnull()) & (source_frame.totalSpent > 3500), \"VIP\"] = True\n",
    "    source_frame[\"VIP\"].fillna(False, inplace=True)\n",
    "    \n",
    "\n",
    "\n",
    "    return source_frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = make_frame_ready(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = make_frame_ready(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = train_data[[\"HomePlanet\", \"CryoSleep\", \"Destination\", \"Age\", \"VIP\", \"RoomService\", \"FoodCourt\", \"ShoppingMall\", \"Spa\", \"VRDeck\", \"Deck\", \"shipSide\", \"totalSpent\", \"NumGroup\", \"AgeGroup\", \"SpendingGroup\", \"Transported\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = test_data[[\"HomePlanet\", \"CryoSleep\", \"Destination\", \"Age\", \"VIP\", \"RoomService\", \"FoodCourt\", \"ShoppingMall\", \"Spa\", \"VRDeck\", \"Deck\", \"shipSide\", \"totalSpent\",\"NumGroup\", \"AgeGroup\", \"SpendingGroup\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_cols = np.where(train_data.dtypes != float)[0][:-1]\n",
    "cat_cols\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.HomePlanet.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.iloc[:, cat_cols] = train_data.iloc[:, cat_cols].fillna(0)\n",
    "\n",
    "train_data = train_data.fillna(train_data.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data.iloc[:, cat_cols] = test_data.iloc[:, cat_cols].fillna(0)\n",
    "\n",
    "test_data = test_data.fillna(test_data.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train_data.drop(columns=[\"Transported\"])\n",
    "\n",
    "y = train_data.Transported"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_cols = np.where(X.dtypes != float)[0]\n",
    "cat_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from catboost import CatBoostClassifier, Pool, cv, metrics\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pool = Pool(X_train, y_train, cat_features=cat_cols)\n",
    "val_pool = Pool(X_val, y_val, cat_features=cat_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CatBoostClassifier(\n",
    "    custom_loss=[metrics.Accuracy()],\n",
    "    random_seed=42,\n",
    "    logging_level=\"Silent\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X_train, y_train,\n",
    "cat_features=cat_cols,\n",
    "eval_set=(X_val, y_val),\n",
    "plot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_params = model.get_params()\n",
    "cv_params[\"loss_function\"] = metrics.Logloss()\n",
    "\n",
    "cv_data = cv(\n",
    "    Pool(X, y, cat_features=cat_cols),\n",
    "    cv_params,\n",
    "    plot=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Best validation accuracy score: {:.2f}Â±{:.2f} on step {}'.format(\n",
    "    np.max(cv_data['test-Accuracy-mean']),\n",
    "    cv_data['test-Accuracy-std'][np.argmax(cv_data['test-Accuracy-mean'])],\n",
    "    np.argmax(cv_data['test-Accuracy-mean'])\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "earlystop_params = cv_params.copy()\n",
    "\n",
    "earlystop_params[\"od_type\"] = \"Iter\"\n",
    "earlystop_params[\"od_wait\"] = 40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_model = CatBoostClassifier(**earlystop_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_model.fit(train_pool, eval_set=val_pool, plot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna\n",
    "\n",
    "def objective(trial):\n",
    "\n",
    "    param ={\n",
    "        \"l2_leaf_reg\": trial.suggest_int(\"l2_leaf_reg\",1, 10),\n",
    "        \"max_depth\": trial.suggest_int(\"max_depth\", 6, 12),\n",
    "        \"learning_rate\": trial.suggest_float(\"learning_rate\", 1e-3, 0.2),\n",
    "        \"random_strength\": trial.suggest_int(\"random_strength\", 1, 6),\n",
    "        \"iterations\": trial.suggest_int(\"iterations\", 500, 1000, 25),\n",
    "        \"eval_metric\": metrics.Accuracy(),\n",
    "        \"loss_function\": metrics.Logloss(),\n",
    "        \"random_seed\": 42,\n",
    "        \"verbose\": False\n",
    "    }\n",
    "\n",
    "    #model = CatBoostClassifier(**param)\n",
    "    #model.fit(train_pool, eval_set=val_pool, verbose=0, early_stopping_rounds=40)\n",
    "\n",
    "    cv_data = cv(Pool(X, y, cat_features=cat_cols), param, logging_level=\"Silent\")\n",
    "\n",
    "    return np.mean(cv_data['test-Accuracy-mean'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "study = optuna.create_study(direction=\"maximize\")\n",
    "study.optimize(objective, n_trials=300, timeout=1800, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_par = study.best_params.copy()\n",
    "best_par[\"eval_metric\"] = metrics.Accuracy()\n",
    "\n",
    "best_mod = CatBoostClassifier(**best_par, cat_features=cat_cols)\n",
    "best_mod.fit(train_pool, eval_set=val_pool ,plot=True, early_stopping_rounds=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.DataFrame()\n",
    "submission[\"PassengerId\"] = sub_ids[\"PassengerId\"]\n",
    "submission[\"Transported\"] = best_mod.predict(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv(\"./submission.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "4f946df053fbf2b937619d3c5458e7af74262f9a954d8797ba0b27400bcafe06"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
